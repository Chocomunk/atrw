{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9790f761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calvinandpogs-ee148 arn:aws:iam::652516965730:role/service-role/AmazonSageMaker-ExecutionRole-20210513T011299\n",
      "/home/ec2-user/SageMaker/atrw/models/yolov5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = 'calvinandpogs-ee148'\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(bucket, role)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5282b44e",
   "metadata": {},
   "source": [
    "## Yolov5s Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "151e23d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TENSORFLOW CONTAINER (PY37)\n",
    "\n",
    "estimator = TensorFlow(entry_point='test.py',\n",
    "                        source_dir='./',\n",
    "                        role=role,\n",
    "                        instance_count=1,\n",
    "                        instance_type=\"ml.g4dn.xlarge\",\n",
    "                        framework_version=\"2.2\",\n",
    "                        py_version=\"py37\",\n",
    "                        hyperparameters={\n",
    "                            'img-size': 1920,\n",
    "                            'task': 'test',\n",
    "                            'weights': 'SM_CHANNEL_MODEL/best.pt',\n",
    "                            'data': 'atrw.yaml',\n",
    "                            'anno-json': 'data/atrw_detect_center.json',\n",
    "                            'output-s3': 's3://calvinandpogs-ee148/atrw/out/detection/yolov5/test/',\n",
    "                            'save-s3': True\n",
    "                        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7965a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({'model': f's3://{bucket}/models/yolov5/train-full/',\n",
    "               'annot_test': f's3://{bucket}/atrw/detection/annotations/yolov5-test/ImageSets',\n",
    "               'label_test': f's3://{bucket}/atrw/detection/annotations/yolov5-test/labels',\n",
    "               'test': f's3://{bucket}/atrw/detection/test/'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83f81f3",
   "metadata": {},
   "source": [
    "## Yolov5m Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99ceb16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TENSORFLOW CONTAINER (PY37)\n",
    "\n",
    "estimator = TensorFlow(entry_point='test.py',\n",
    "                        source_dir='./',\n",
    "                        role=role,\n",
    "                        instance_count=1,\n",
    "                        instance_type=\"ml.g4dn.xlarge\",\n",
    "                        framework_version=\"2.2\",\n",
    "                        py_version=\"py37\",\n",
    "                        hyperparameters={\n",
    "                            'img-size': 1920,\n",
    "                            'task': 'test',\n",
    "                            'weights': 'SM_CHANNEL_MODEL/best.pt',\n",
    "                            'data': 'atrw.yaml',\n",
    "                            'anno-json': 'data/atrw_detect_corner.json',\n",
    "                            'output-s3': 's3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-m/',\n",
    "                            'save-s3': True\n",
    "                        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9940261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-26 23:05:55 Starting - Starting the training job...\n",
      "2021-05-26 23:06:21 Starting - Launching requested ML instancesProfilerReport-1622070350: InProgress\n",
      "......\n",
      "2021-05-26 23:07:21 Starting - Preparing the instances for training......\n",
      "2021-05-26 23:08:23 Downloading - Downloading input data......\n",
      "2021-05-26 23:09:21 Training - Downloading the training image...\n",
      "2021-05-26 23:09:41 Training - Training image download completed. Training in progress.\u001b[34m2021-05-26 23:09:37.949997: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:425] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-05-26 23:09:37.953471: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:106] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2021-05-26 23:09:38.052589: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:425] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-05-26 23:09:40,674 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2021-05-26 23:09:41,866 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.7 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting matplotlib>=3.2.2\n",
      "  Downloading matplotlib-3.4.2-cp37-cp37m-manylinux1_x86_64.whl (10.3 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (1.18.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (4.2.0.32)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Pillow in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (7.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 8)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 9)) (1.4.1)\u001b[0m\n",
      "\u001b[34mCollecting torch>=1.7.0\n",
      "  Downloading torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1 MB)\u001b[0m\n",
      "\u001b[34mCollecting torchvision>=0.8.1\n",
      "  Downloading torchvision-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (17.4 MB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm>=4.41.0\n",
      "  Downloading tqdm-4.61.0-py2.py3-none-any.whl (75 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard>=2.4.1\n",
      "  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\u001b[0m\n",
      "\u001b[34mCollecting seaborn>=0.11.0\n",
      "  Downloading seaborn-0.11.1-py3-none-any.whl (285 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 20)) (1.0.3)\u001b[0m\n",
      "\u001b[34mCollecting thop\n",
      "  Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting Cython\n",
      "  Downloading Cython-0.29.23-cp37-cp37m-manylinux1_x86_64.whl (2.0 MB)\u001b[0m\n",
      "\u001b[34mCollecting pycocotools>=2.0\n",
      "  Downloading pycocotools-2.0.2.tar.gz (23 kB)\u001b[0m\n",
      "\u001b[34mCollecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.1)\u001b[0m\n",
      "\u001b[34mCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/site-packages (from pycocotools>=2.0->-r requirements.txt (line 30)) (54.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas->-r requirements.txt (line 20)) (2021.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.36.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (2.23.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.36.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.15.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.27.0)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/site-packages (from torch>=1.7.0->-r requirements.txt (line 10)) (3.7.4.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.15.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.2.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.4.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.25.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (2020.12.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.4.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for pycocotools (setup.py): finished with status 'done'\n",
      "  Created wheel for pycocotools: filename=pycocotools-2.0.2-cp37-cp37m-linux_x86_64.whl size=273719 sha256=36a6119535b773124e0159ff05889d510df2ca9c285f0726d8c18de229decba3\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/cf/1b/e95c99c5f9d1648be3f500ca55e7ce55f24818b0f48336adaf\u001b[0m\n",
      "\u001b[34mSuccessfully built pycocotools\u001b[0m\n",
      "\u001b[34mInstalling collected packages: kiwisolver, cycler, torch, tensorboard-data-server, matplotlib, Cython, tqdm, torchvision, thop, tensorboard, seaborn, pycocotools\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.2.2\n",
      "    Uninstalling tensorboard-2.2.2:\n",
      "      Successfully uninstalled tensorboard-2.2.2\u001b[0m\n",
      "\u001b[34mSuccessfully installed Cython-0.29.23 cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.4.2 pycocotools-2.0.2 seaborn-0.11.1 tensorboard-2.5.0 tensorboard-data-server-0.6.1 thop-0.0.31.post2005241907 torch-1.8.1 torchvision-0.9.1 tqdm-4.61.0\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34mtensorflow-gpu 2.2.2 requires tensorboard<2.3.0,>=2.2.0, but you have tensorboard 2.5.0 which is incompatible.\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 21.0.1; however, version 21.1.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\n",
      "\u001b[0m\n",
      "\u001b[34m2021-05-26 23:10:32,141 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"label_test\": \"/opt/ml/input/data/label_test\",\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"annot_test\": \"/opt/ml/input/data/annot_test\",\n",
      "        \"model\": \"/opt/ml/input/data/model\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"output-s3\": \"s3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-m/\",\n",
      "        \"data\": \"atrw.yaml\",\n",
      "        \"weights\": \"SM_CHANNEL_MODEL/best.pt\",\n",
      "        \"save-s3\": true,\n",
      "        \"task\": \"test\",\n",
      "        \"anno-json\": \"data/atrw_detect_corner.json\",\n",
      "        \"model_dir\": \"s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-26-23-05-50-704/model\",\n",
      "        \"img-size\": 1920\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"label_test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"annot_test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"model\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tensorflow-training-2021-05-26-23-05-50-704\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-26-23-05-50-704/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"test\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"test.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"anno-json\":\"data/atrw_detect_corner.json\",\"data\":\"atrw.yaml\",\"img-size\":1920,\"model_dir\":\"s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-26-23-05-50-704/model\",\"output-s3\":\"s3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-m/\",\"save-s3\":true,\"task\":\"test\",\"weights\":\"SM_CHANNEL_MODEL/best.pt\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=test.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"annot_test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"label_test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"model\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"annot_test\",\"label_test\",\"model\",\"test\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=test\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-26-23-05-50-704/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"annot_test\":\"/opt/ml/input/data/annot_test\",\"label_test\":\"/opt/ml/input/data/label_test\",\"model\":\"/opt/ml/input/data/model\",\"test\":\"/opt/ml/input/data/test\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"anno-json\":\"data/atrw_detect_corner.json\",\"data\":\"atrw.yaml\",\"img-size\":1920,\"model_dir\":\"s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-26-23-05-50-704/model\",\"output-s3\":\"s3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-m/\",\"save-s3\":true,\"task\":\"test\",\"weights\":\"SM_CHANNEL_MODEL/best.pt\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"annot_test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"label_test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"model\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2021-05-26-23-05-50-704\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-26-23-05-50-704/source/sourcedir.tar.gz\",\"module_name\":\"test\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"test.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--anno-json\",\"data/atrw_detect_corner.json\",\"--data\",\"atrw.yaml\",\"--img-size\",\"1920\",\"--model_dir\",\"s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-26-23-05-50-704/model\",\"--output-s3\",\"s3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-m/\",\"--save-s3\",\"True\",\"--task\",\"test\",\"--weights\",\"SM_CHANNEL_MODEL/best.pt\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_LABEL_TEST=/opt/ml/input/data/label_test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_ANNOT_TEST=/opt/ml/input/data/annot_test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_MODEL=/opt/ml/input/data/model\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT-S3=s3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-m/\u001b[0m\n",
      "\u001b[34mSM_HP_DATA=atrw.yaml\u001b[0m\n",
      "\u001b[34mSM_HP_WEIGHTS=SM_CHANNEL_MODEL/best.pt\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE-S3=true\u001b[0m\n",
      "\u001b[34mSM_HP_TASK=test\u001b[0m\n",
      "\u001b[34mSM_HP_ANNO-JSON=data/atrw_detect_corner.json\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-26-23-05-50-704/model\u001b[0m\n",
      "\u001b[34mSM_HP_IMG-SIZE=1920\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.7 test.py --anno-json data/atrw_detect_corner.json --data atrw.yaml --img-size 1920 --model_dir s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-26-23-05-50-704/model --output-s3 s3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-m/ --save-s3 True --task test --weights SM_CHANNEL_MODEL/best.pt\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mNamespace(anno_json='data/atrw_detect_corner.json', augment=False, batch_size=32, conf_thres=0.001, data='./data/atrw.yaml', device='', exist_ok=False, img_size=1920, iou_thres=0.6, model_dir='s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-26-23-05-50-704/model', name='exp', output_s3='s3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-m/', project='runs/test', save_conf=True, save_hybrid=False, save_json=True, save_s3=True, save_txt=True, single_cls=False, task='test', verbose=False, weights=['/opt/ml/input/data/model/best.pt'])\u001b[0m\n",
      "\u001b[34mWARNING: Dataset not found, nonexistent paths: ['/opt/ml/code/val.txt']\u001b[0m\n",
      "\u001b[34mRunning bash data/scripts/setup_tiger.sh ...\u001b[0m\n",
      "\u001b[34m------------------------------SETUP ATRW-----------------------------------\u001b[0m\n",
      "\u001b[34mDataset autodownload success\n",
      "\u001b[0m\n",
      "\u001b[34m                 all        1651        3609       0.837       0.656       0.716       0.356\u001b[0m\n",
      "\u001b[34mSpeed: 47.9/0.9/48.8 ms inference/NMS/total per 1920x1920 image at batch-size 32\u001b[0m\n",
      "\u001b[34mEvaluating pycocotools mAP... saving runs/test/exp/best_predictions.json...\u001b[0m\n",
      "\u001b[34mloading annotations into memory...\u001b[0m\n",
      "\u001b[34mDone (t=0.01s)\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mLoading and preparing results...\u001b[0m\n",
      "\u001b[34mDONE (t=0.13s)\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mRunning per image evaluation...\u001b[0m\n",
      "\u001b[34mEvaluate annotation type *bbox*\u001b[0m\n",
      "\u001b[34mDONE (t=0.28s).\u001b[0m\n",
      "\u001b[34mAccumulating evaluation results...\u001b[0m\n",
      "\u001b[34mDONE (t=0.13s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\u001b[0m\n",
      "\u001b[34mResults saved to runs/test/exp\u001b[0m\n",
      "\u001b[34m1651 labels saved to runs/test/exp/labels\u001b[0m\n",
      "\u001b[34mExecuting: aws s3 cp --recursive runs/test/exp s3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-m/05-26-2021-23-12-19/runs/\u001b[0m\n",
      "\u001b[34mYOLOv5 ðŸš€ 2021-5-23 torch 1.8.1+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n",
      "\u001b[0m\n",
      "\u001b[34mFusing layers... \u001b[0m\n",
      "\u001b[34mModel Summary: 308 layers, 21037638 parameters, 0 gradients, 50.3 GFLOPS\u001b[0m\n",
      "\u001b[34m#015Scanning images:   0%|          | 0/1651 [00:00<?, ?it/s]#015#033[34m#033[1mtest: #033[0mScanning 'test' images and labels... 187 found, 0 missing, 0 empty, 0 corrupted:  11%|â–ˆâ–        | 187/1651 [00:00<00:00, 1869.47it/s]#015#033[34m#033[1mtest: #033[0mScanning 'test' images and labels... 378 found, 0 missing, 0 empty, 0 corrupted:  23%|â–ˆâ–ˆâ–Ž       | 378/1651 [00:00<00:00, 1889.58it/s]#015#033[34m#033[1mtest: #033[0mScanning 'test' images and labels... 577 found, 0 missing, 0 empty, 0 corrupted:  35%|â–ˆâ–ˆâ–ˆâ–      | 577/1651 [00:00<00:00, 1931.55it/s]#015#033[34m#033[1mtest: #033[0mScanning 'test' images and labels... 778 found, 0 missing, 0 empty, 0 corrupted:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 778/1651 [00:00<00:00, 1961.62it/s]#015#033[34m#033[1mtest: #033[0mScanning 'test' images and labels... 975 found, 0 missing, 0 empty, 0 corrupted:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 975/1651 [00:00<00:00, 1828.69it/s]#015#033[34m#033[1mtest: #033[0mScanning 'test' images and labels... 1163 found, 0 missing, 0 empty, 0 corrupted:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1163/1651 [00:00<00:00, 1842.40it/s]#015#033[34m#033[1mtest: #033[0mScanning 'test' images and labels... 1418 found, 0 missing, 0 empty, 0 corrupted:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1418/1651 [00:00<00:00, 2064.52it/s]#015#033[34m#033[1mtest: #033[0mScanning 'test' images and labels... 1651 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1651/1651 [00:00<00:00, 2107.17it/s]\u001b[0m\n",
      "\u001b[34m#033[34m#033[1mtest: #033[0mNew cache created: test.cache\u001b[0m\n",
      "\u001b[34m#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   0%|          | 0/52 [00:00<?, ?it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   2%|â–         | 1/52 [00:05<04:40,  5.50s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   4%|â–         | 2/52 [00:08<03:25,  4.10s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   6%|â–Œ         | 3/52 [00:11<02:46,  3.39s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   8%|â–Š         | 4/52 [00:13<02:19,  2.91s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  10%|â–‰         | 5/52 [00:15<01:57,  2.50s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  12%|â–ˆâ–        | 6/52 [00:16<01:43,  2.26s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  13%|â–ˆâ–Ž        | 7/52 [00:18<01:33,  2.09s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  15%|â–ˆâ–Œ        | 8/52 [00:20<01:27,  1.98s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  17%|â–ˆâ–‹        | 9/52 [00:22<01:22,  1.92s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  19%|â–ˆâ–‰        | 10/52 [00:23<01:17,  1.86s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  21%|â–ˆâ–ˆ        | 11/52 [00:25<01:14,  1.82s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  23%|â–ˆâ–ˆâ–Ž       | 12/52 [00:27<01:11,  1.79s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  25%|â–ˆâ–ˆâ–Œ       | 13/52 [00:29<01:10,  1.81s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  27%|â–ˆâ–ˆâ–‹       | 14/52 [00:30<01:07,  1.79s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  29%|â–ˆâ–ˆâ–‰       | 15/52 [00:32<01:05,  1.77s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  31%|â–ˆâ–ˆâ–ˆ       | 16/52 [00:34<01:03,  1.76s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 17/52 [00:36<01:01,  1.75s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  35%|â–ˆâ–ˆâ–ˆâ–      | 18/52 [00:37<00:59,  1.75s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 19/52 [00:39<00:57,  1.75s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 20/52 [00:41<00:55,  1.75s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 21/52 [00:43<00:53,  1.74s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/52 [00:44<00:52,  1.75s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 23/52 [00:46<00:50,  1.74s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 24/52 [00:48<00:48,  1.75s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 25/52 [00:50<00:47,  1.74s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 26/52 [00:51<00:45,  1.75s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/52 [00:53<00:43,  1.74s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 28/52 [00:55<00:42,  1.75s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 29/52 [00:57<00:40,  1.76s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 30/52 [00:58<00:38,  1.75s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 31/52 [01:00<00:36,  1.76s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/52 [01:02<00:35,  1.76s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 33/52 [01:04<00:33,  1.76s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 34/52 [01:05<00:31,  1.76s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 35/52 [01:07<00:29,  1.76s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 36/52 [01:09<00:28,  1.77s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 37/52 [01:11<00:26,  1.77s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 38/52 [01:13<00:24,  1.77s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 39/52 [01:14<00:23,  1.78s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 40/52 [01:16<00:21,  1.80s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 41/52 [01:18<00:19,  1.79s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 42/52 [01:20<00:17,  1.79s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 43/52 [01:22<00:16,  1.80s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 44/52 [01:23<00:14,  1.80s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 45/52 [01:25<00:12,  1.80s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 46/52 [01:27<00:10,  1.81s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 47/52 [01:29<00:09,  1.82s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 48/52 [01:31<00:07,  1.82s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 49/52 [01:32<00:05,  1.81s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 50/52 [01:34<00:03,  1.80s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 51/52 [01:36<00:01,  1.80s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [01:37<00:00,  1.58s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [01:37<00:00,  1.88s/it]\n",
      "\u001b[0m\n",
      "\u001b[34m2021-05-26 23:12:29,314 sagemaker_tensorflow_container.training WARNING  No model artifact is saved under path /opt/ml/model. Your training job will not save any model files to S3.\u001b[0m\n",
      "\u001b[34mFor details of how to construct your training script see:\u001b[0m\n",
      "\u001b[34mhttps://sagemaker.readthedocs.io/en/stable/using_tf.html#adapting-your-local-tensorflow-script\u001b[0m\n",
      "\u001b[34m2021-05-26 23:12:29,314 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-05-26 23:12:42 Uploading - Uploading generated training model\n",
      "2021-05-26 23:12:42 Completed - Training job completed\n",
      "Training seconds: 252\n",
      "Billable seconds: 252\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'model': f's3://{bucket}/models/yolov5/train-full-m/',\n",
    "               'annot_test': f's3://{bucket}/atrw/detection/annotations/yolov5-test/ImageSets',\n",
    "               'label_test': f's3://{bucket}/atrw/detection/annotations/yolov5-test/labels',\n",
    "               'test': f's3://{bucket}/atrw/detection/test/'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1046549e",
   "metadata": {},
   "source": [
    "## Testing Subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0218b59d",
   "metadata": {},
   "source": [
    "### Fractional Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94fb2bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "\n",
    "sets = [16, 8, 4, 2]\n",
    "\n",
    "for set in sets:\n",
    "    estimator = TensorFlow(entry_point='test.py',\n",
    "                            source_dir='./',\n",
    "                            role=role,\n",
    "                            instance_count=1,\n",
    "                            instance_type=\"ml.g4dn.xlarge\",\n",
    "                            framework_version=\"2.2\",\n",
    "                            py_version=\"py37\",\n",
    "                            hyperparameters={\n",
    "                                'img-size': 1920,\n",
    "                                'task': 'test',\n",
    "                                'weights': 'SM_CHANNEL_MODEL/best.pt',\n",
    "                                'data': f'atrw{set}.yaml',\n",
    "                                'anno-json': 'data/atrw_detect_center.json',\n",
    "                                'output-s3': f's3://calvinandpogs-ee148/atrw/out/detection/yolov5/frac/test{set}/',\n",
    "                                'save-s3': True\n",
    "                            }\n",
    "    )\n",
    "    estimator.fit({'model': f's3://{bucket}/models/yolov5/train{set}/',\n",
    "                   'annot_test': f's3://{bucket}/atrw/detection/annotations/yolov5-test/ImageSets',\n",
    "                   'label_test': f's3://{bucket}/atrw/detection/annotations/yolov5-test/labels',\n",
    "                   'test': f's3://{bucket}/atrw/detection/test/'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaa3aa2",
   "metadata": {},
   "source": [
    "### Clustering Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66d23128",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "\n",
    "sets = [16, 8, 4, 2]\n",
    "\n",
    "for set in sets:\n",
    "    estimator = TensorFlow(entry_point='test.py',\n",
    "                            source_dir='./',\n",
    "                            role=role,\n",
    "                            instance_count=1,\n",
    "                            instance_type=\"ml.g4dn.xlarge\",\n",
    "                            framework_version=\"2.2\",\n",
    "                            py_version=\"py37\",\n",
    "                            hyperparameters={\n",
    "                                'img-size': 1920,\n",
    "                                'task': 'test',\n",
    "                                'weights': 'SM_CHANNEL_MODEL/best.pt',\n",
    "                                'data': 'atrw.yaml',\n",
    "                                'anno-json': 'data/atrw_detect_center.json',\n",
    "                                'output-s3': f's3://calvinandpogs-ee148/atrw/out/detection/yolov5/bg-split/test/split{set}/',\n",
    "                                'save-s3': True\n",
    "                            }\n",
    "    )\n",
    "    estimator.fit({'model': f's3://{bucket}/models/yolov5/bg-split/split{set}/',\n",
    "                   'annot_test': f's3://{bucket}/atrw/detection/annotations/yolov5-test/ImageSets',\n",
    "                   'label_test': f's3://{bucket}/atrw/detection/annotations/yolov5-test/labels',\n",
    "                   'test': f's3://{bucket}/atrw/detection/test/'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab3c97a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_latest_p37",
   "language": "python",
   "name": "conda_mxnet_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
