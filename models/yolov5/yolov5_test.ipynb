{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e17cdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calvinandpogs-ee148 arn:aws:iam::652516965730:role/service-role/AmazonSageMaker-ExecutionRole-20210513T011299\n",
      "/home/ec2-user/SageMaker/atrw/models/yolov5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = 'calvinandpogs-ee148'\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(bucket, role)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48370155",
   "metadata": {},
   "source": [
    "## Yolov5s Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3463c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TENSORFLOW CONTAINER (PY37)\n",
    "\n",
    "image_set = 'train'\n",
    "\n",
    "estimator = TensorFlow(entry_point='test.py',\n",
    "                        source_dir='./',\n",
    "                        role=role,\n",
    "                        instance_count=1,\n",
    "                        instance_type=\"ml.g4dn.xlarge\",\n",
    "                        framework_version=\"2.2\",\n",
    "                        py_version=\"py37\",\n",
    "                        hyperparameters={\n",
    "                            'img-size': 1920,\n",
    "                            'task': image_set,\n",
    "                            'weights': 'SM_CHANNEL_MODEL/best.pt',\n",
    "                            'data': 'atrw.yaml',\n",
    "                            'anno-json': 'data/atrw_detect_center.json',\n",
    "                            'output-s3': f's3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-s/{image_set}',\n",
    "                            'save-s3': True\n",
    "                        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04106dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-29 03:20:50 Starting - Starting the training job...\n",
      "2021-05-29 03:21:00 Starting - Launching requested ML instancesProfilerReport-1622258446: InProgress\n",
      "......\n",
      "2021-05-29 03:22:07 Starting - Preparing the instances for training......\n",
      "2021-05-29 03:23:19 Downloading - Downloading input data.........\n",
      "2021-05-29 03:24:43 Training - Downloading the training image..\u001b[34m2021-05-29 03:25:01.685285: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:425] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-05-29 03:25:01.689110: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:106] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2021-05-29 03:25:01.816235: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:425] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-05-29 03:25:04,906 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\n",
      "2021-05-29 03:25:02 Training - Training image download completed. Training in progress.\u001b[34m2021-05-29 03:25:09,095 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.7 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting matplotlib>=3.2.2\n",
      "  Downloading matplotlib-3.4.2-cp37-cp37m-manylinux1_x86_64.whl (10.3 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (1.18.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (4.2.0.32)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Pillow in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (7.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 8)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 9)) (1.4.1)\u001b[0m\n",
      "\u001b[34mCollecting torch>=1.7.0\u001b[0m\n",
      "\u001b[34m  Downloading torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1 MB)\u001b[0m\n",
      "\u001b[34mCollecting torchvision>=0.8.1\n",
      "  Downloading torchvision-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (17.4 MB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm>=4.41.0\n",
      "  Downloading tqdm-4.61.0-py2.py3-none-any.whl (75 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard>=2.4.1\n",
      "  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\u001b[0m\n",
      "\u001b[34mCollecting seaborn>=0.11.0\n",
      "  Downloading seaborn-0.11.1-py3-none-any.whl (285 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 20)) (1.0.3)\u001b[0m\n",
      "\u001b[34mCollecting thop\n",
      "  Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting Cython\n",
      "  Downloading Cython-0.29.23-cp37-cp37m-manylinux1_x86_64.whl (2.0 MB)\u001b[0m\n",
      "\u001b[34mCollecting pycocotools>=2.0\n",
      "  Downloading pycocotools-2.0.2.tar.gz (23 kB)\u001b[0m\n",
      "\u001b[34mCollecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.4.7)\u001b[0m\n",
      "\u001b[34mCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/site-packages (from pycocotools>=2.0->-r requirements.txt (line 30)) (54.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas->-r requirements.txt (line 20)) (2021.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.9.0)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.36.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.27.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.36.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.15.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (2.23.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/site-packages (from torch>=1.7.0->-r requirements.txt (line 10)) (3.7.4.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.15.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.2.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.4.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (2020.12.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.25.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.4.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for pycocotools (setup.py): finished with status 'done'\n",
      "  Created wheel for pycocotools: filename=pycocotools-2.0.2-cp37-cp37m-linux_x86_64.whl size=273715 sha256=0d6b52438cb9b7f7916269c7990636ab801ebfe48afa4cefe3e27701c662c036\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/cf/1b/e95c99c5f9d1648be3f500ca55e7ce55f24818b0f48336adaf\u001b[0m\n",
      "\u001b[34mSuccessfully built pycocotools\u001b[0m\n",
      "\u001b[34mInstalling collected packages: kiwisolver, cycler, torch, tensorboard-data-server, matplotlib, Cython, tqdm, torchvision, thop, tensorboard, seaborn, pycocotools\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.2.2\n",
      "    Uninstalling tensorboard-2.2.2:\n",
      "      Successfully uninstalled tensorboard-2.2.2\u001b[0m\n",
      "\u001b[34mSuccessfully installed Cython-0.29.23 cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.4.2 pycocotools-2.0.2 seaborn-0.11.1 tensorboard-2.5.0 tensorboard-data-server-0.6.1 thop-0.0.31.post2005241907 torch-1.8.1 torchvision-0.9.1 tqdm-4.61.0\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34mtensorflow-gpu 2.2.2 requires tensorboard<2.3.0,>=2.2.0, but you have tensorboard 2.5.0 which is incompatible.\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 21.0.1; however, version 21.1.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\n",
      "\u001b[0m\n",
      "\u001b[34m2021-05-29 03:25:52,903 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"label_test\": \"/opt/ml/input/data/label_test\",\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"annot_test\": \"/opt/ml/input/data/annot_test\",\n",
      "        \"model\": \"/opt/ml/input/data/model\",\n",
      "        \"label\": \"/opt/ml/input/data/label\",\n",
      "        \"annot\": \"/opt/ml/input/data/annot\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"output-s3\": \"s3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-s/train\",\n",
      "        \"data\": \"atrw.yaml\",\n",
      "        \"weights\": \"SM_CHANNEL_MODEL/best.pt\",\n",
      "        \"save-s3\": true,\n",
      "        \"task\": \"train\",\n",
      "        \"anno-json\": \"data/atrw_detect_center.json\",\n",
      "        \"model_dir\": \"s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-29-02-59-57-745/model\",\n",
      "        \"img-size\": 1920\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"label_test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"annot_test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"model\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"label\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"annot\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tensorflow-training-2021-05-29-03-20-46-110\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-29-03-20-46-110/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"test\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"test.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"anno-json\":\"data/atrw_detect_center.json\",\"data\":\"atrw.yaml\",\"img-size\":1920,\"model_dir\":\"s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-29-02-59-57-745/model\",\"output-s3\":\"s3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-s/train\",\"save-s3\":true,\"task\":\"train\",\"weights\":\"SM_CHANNEL_MODEL/best.pt\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=test.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"annot\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"annot_test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"label\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"label_test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"model\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"annot\",\"annot_test\",\"label\",\"label_test\",\"model\",\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=test\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-29-03-20-46-110/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"annot\":\"/opt/ml/input/data/annot\",\"annot_test\":\"/opt/ml/input/data/annot_test\",\"label\":\"/opt/ml/input/data/label\",\"label_test\":\"/opt/ml/input/data/label_test\",\"model\":\"/opt/ml/input/data/model\",\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"anno-json\":\"data/atrw_detect_center.json\",\"data\":\"atrw.yaml\",\"img-size\":1920,\"model_dir\":\"s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-29-02-59-57-745/model\",\"output-s3\":\"s3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-s/train\",\"save-s3\":true,\"task\":\"train\",\"weights\":\"SM_CHANNEL_MODEL/best.pt\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"annot\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"annot_test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"label\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"label_test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"model\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2021-05-29-03-20-46-110\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-29-03-20-46-110/source/sourcedir.tar.gz\",\"module_name\":\"test\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"test.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--anno-json\",\"data/atrw_detect_center.json\",\"--data\",\"atrw.yaml\",\"--img-size\",\"1920\",\"--model_dir\",\"s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-29-02-59-57-745/model\",\"--output-s3\",\"s3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-s/train\",\"--save-s3\",\"True\",\"--task\",\"train\",\"--weights\",\"SM_CHANNEL_MODEL/best.pt\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_LABEL_TEST=/opt/ml/input/data/label_test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_ANNOT_TEST=/opt/ml/input/data/annot_test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_MODEL=/opt/ml/input/data/model\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_LABEL=/opt/ml/input/data/label\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_ANNOT=/opt/ml/input/data/annot\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT-S3=s3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-s/train\u001b[0m\n",
      "\u001b[34mSM_HP_DATA=atrw.yaml\u001b[0m\n",
      "\u001b[34mSM_HP_WEIGHTS=SM_CHANNEL_MODEL/best.pt\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE-S3=true\u001b[0m\n",
      "\u001b[34mSM_HP_TASK=train\u001b[0m\n",
      "\u001b[34mSM_HP_ANNO-JSON=data/atrw_detect_center.json\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-29-02-59-57-745/model\u001b[0m\n",
      "\u001b[34mSM_HP_IMG-SIZE=1920\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.7 test.py --anno-json data/atrw_detect_center.json --data atrw.yaml --img-size 1920 --model_dir s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-29-02-59-57-745/model --output-s3 s3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-s/train --save-s3 True --task train --weights SM_CHANNEL_MODEL/best.pt\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mNamespace(anno_json='data/atrw_detect_center.json', augment=False, batch_size=32, conf_thres=0.001, data='./data/atrw.yaml', device='', exist_ok=False, img_size=1920, iou_thres=0.6, model_dir='s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-29-02-59-57-745/model', name='exp', output_s3='s3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-s/train', project='runs/test', save_conf=True, save_hybrid=False, save_json=True, save_s3=True, save_txt=True, single_cls=False, task='train', verbose=False, weights=['/opt/ml/input/data/model/best.pt'])\u001b[0m\n",
      "\u001b[34mWARNING: Dataset not found, nonexistent paths: ['/opt/ml/code/val.txt']\u001b[0m\n",
      "\u001b[34mRunning bash data/scripts/setup_tiger.sh ...\u001b[0m\n",
      "\u001b[34m------------------------------SETUP ATRW-----------------------------------\u001b[0m\n",
      "\u001b[34m------------------------------COPIED FILES-----------------------------------\u001b[0m\n",
      "\u001b[34m__init__.py\u001b[0m\n",
      "\u001b[34mdata\u001b[0m\n",
      "\u001b[34mdetect.py\u001b[0m\n",
      "\u001b[34mhubconf.py\u001b[0m\n",
      "\u001b[34mmodels\u001b[0m\n",
      "\u001b[34mrequirements.txt\u001b[0m\n",
      "\u001b[34mruns\u001b[0m\n",
      "\u001b[34mtest.py\u001b[0m\n",
      "\u001b[34mtrain.py\u001b[0m\n",
      "\u001b[34mtrain.txt\u001b[0m\n",
      "\u001b[34mtutorial.ipynb\u001b[0m\n",
      "\u001b[34mutils\u001b[0m\n",
      "\u001b[34mval.txt\u001b[0m\n",
      "\u001b[34mweights\u001b[0m\n",
      "\u001b[34myolov5_predict.ipynb\u001b[0m\n",
      "\u001b[34myolov5_test.ipynb\u001b[0m\n",
      "\u001b[34myolov5_train.ipynb\u001b[0m\n",
      "\u001b[34m------------------------------COPIED FILES-----------------------------------\u001b[0m\n",
      "\u001b[34mtrain.txt\u001b[0m\n",
      "\u001b[34mval.txt\u001b[0m\n",
      "\u001b[34mDataset autodownload success\n",
      "\u001b[0m\n",
      "\u001b[34m                 all        2485        5341       0.829       0.714       0.766       0.382\u001b[0m\n",
      "\u001b[34mSpeed: 20.3/1.1/21.4 ms inference/NMS/total per 1920x1920 image at batch-size 32\n",
      "\u001b[0m\n",
      "\u001b[34mEvaluating pycocotools mAP... saving runs/test/exp/best_predictions.json...\u001b[0m\n",
      "\u001b[34mloading annotations into memory...\u001b[0m\n",
      "\u001b[34mDone (t=0.01s)\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mLoading and preparing results...\u001b[0m\n",
      "\u001b[34mpycocotools unable to run: Results do not correspond to current coco set\u001b[0m\n",
      "\u001b[34mResults saved to runs/test/exp\u001b[0m\n",
      "\u001b[34m2485 labels saved to runs/test/exp/labels\u001b[0m\n",
      "\u001b[34mExecuting: aws s3 cp --recursive runs/test/exp s3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-s/train/05-29-2021-03-27-33/runs/\u001b[0m\n",
      "\n",
      "2021-05-29 03:27:55 Uploading - Uploading generated training model\n",
      "2021-05-29 03:27:55 Completed - Training job completed\n",
      "\u001b[34mYOLOv5 ðŸš€ 2021-5-23 torch 1.8.1+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n",
      "\u001b[0m\n",
      "\u001b[34mFusing layers... \u001b[0m\n",
      "\u001b[34mModel Summary: 224 layers, 7053910 parameters, 0 gradients, 16.3 GFLOPS\u001b[0m\n",
      "\u001b[34m#015Scanning images:   0%|          | 0/2485 [00:00<?, ?it/s]#015#033[34m#033[1mtrain: #033[0mScanning 'train' images and labels... 151 found, 0 missing, 0 empty, 0 corrupted:   6%|â–Œ         | 151/2485 [00:00<00:01, 1504.41it/s]#015#033[34m#033[1mtrain: #033[0mScanning 'train' images and labels... 327 found, 0 missing, 0 empty, 0 corrupted:  13%|â–ˆâ–Ž        | 327/2485 [00:00<00:01, 1650.24it/s]#015#033[34m#033[1mtrain: #033[0mScanning 'train' images and labels... 493 found, 0 missing, 0 empty, 0 corrupted:  20%|â–ˆâ–‰        | 493/2485 [00:00<00:01, 1638.11it/s]#015#033[34m#033[1mtrain: #033[0mScanning 'train' images and labels... 657 found, 0 missing, 0 empty, 0 corrupted:  26%|â–ˆâ–ˆâ–‹       | 657/2485 [00:00<00:01, 1598.23it/s]#015#033[34m#033[1mtrain: #033[0mScanning 'train' images and labels... 817 found, 0 missing, 0 empty, 0 corrupted:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 817/2485 [00:00<00:01, 1576.64it/s]#015#033[34m#033[1mtrain: #033[0mScanning 'train' images and labels... 1003 found, 0 missing, 0 empty, 0 corrupted:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1003/2485 [00:00<00:00, 1669.15it/s]#015#033[34m#033[1mtrain: #033[0mScanning 'train' images and labels... 1206 found, 0 missing, 0 empty, 0 corrupted:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1206/2485 [00:00<00:00, 1783.37it/s]#015#033[34m#033[1mtrain: #033[0mScanning 'train' images and labels... 1410 found, 0 missing, 0 empty, 0 corrupted:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1410/2485 [00:00<00:00, 1862.84it/s]#015#033[34m#033[1mtrain: #033[0mScanning 'train' images and labels... 1613 found, 0 missing, 0 empty, 0 corrupted:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1613/2485 [00:00<00:00, 1912.16it/s]#015#033[34m#033[1mtrain: #033[0mScanning 'train' images and labels... 1821 found, 0 missing, 0 empty, 0 corrupted:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1821/2485 [00:01<00:00, 1961.74it/s]#015#033[34m#033[1mtrain: #033[0mScanning 'train' images and labels... 2023 found, 0 missing, 0 empty, 0 corrupted:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2023/2485 [00:01<00:00, 1978.39it/s]#015#033[34m#033[1mtrain: #033[0mScanning 'train' images and labels... 2289 found, 0 missing, 0 empty, 0 corrupted:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2289/2485 [00:01<00:00, 2183.76it/s]#015#033[34m#033[1mtrain: #033[0mScanning 'train' images and labels... 2485 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2485/2485 [00:01<00:00, 1967.57it/s]\u001b[0m\n",
      "\u001b[34m#033[34m#033[1mtrain: #033[0mNew cache created: train.cache\u001b[0m\n",
      "\u001b[34m#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   0%|          | 0/78 [00:00<?, ?it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   1%|â–         | 1/78 [00:05<06:43,  5.24s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   3%|â–Ž         | 2/78 [00:07<04:41,  3.70s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   4%|â–         | 3/78 [00:09<03:33,  2.85s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   5%|â–Œ         | 4/78 [00:11<02:47,  2.26s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   6%|â–‹         | 5/78 [00:12<02:13,  1.83s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   8%|â–Š         | 6/78 [00:13<01:52,  1.56s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   9%|â–‰         | 7/78 [00:14<01:37,  1.37s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  10%|â–ˆ         | 8/78 [00:15<01:26,  1.24s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  12%|â–ˆâ–        | 9/78 [00:15<01:17,  1.12s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  13%|â–ˆâ–Ž        | 10/78 [00:16<01:12,  1.06s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  14%|â–ˆâ–        | 11/78 [00:17<01:10,  1.05s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  15%|â–ˆâ–Œ        | 12/78 [00:18<01:07,  1.03s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  17%|â–ˆâ–‹        | 13/78 [00:19<01:03,  1.02it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  18%|â–ˆâ–Š        | 14/78 [00:20<01:03,  1.01it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  19%|â–ˆâ–‰        | 15/78 [00:21<01:00,  1.04it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  21%|â–ˆâ–ˆ        | 16/78 [00:22<01:00,  1.03it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  22%|â–ˆâ–ˆâ–       | 17/78 [00:23<00:57,  1.05it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  23%|â–ˆâ–ˆâ–Ž       | 18/78 [00:24<00:56,  1.05it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  24%|â–ˆâ–ˆâ–       | 19/78 [00:25<00:56,  1.05it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  26%|â–ˆâ–ˆâ–Œ       | 20/78 [00:26<00:55,  1.04it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  27%|â–ˆâ–ˆâ–‹       | 21/78 [00:27<00:55,  1.02it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  28%|â–ˆâ–ˆâ–Š       | 22/78 [00:28<00:53,  1.04it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  29%|â–ˆâ–ˆâ–‰       | 23/78 [00:29<00:51,  1.06it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  31%|â–ˆâ–ˆâ–ˆ       | 24/78 [00:30<00:50,  1.07it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  32%|â–ˆâ–ˆâ–ˆâ–      | 25/78 [00:31<00:50,  1.04it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 26/78 [00:32<00:50,  1.03it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  35%|â–ˆâ–ˆâ–ˆâ–      | 27/78 [00:33<00:51,  1.00s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 28/78 [00:34<00:49,  1.01it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 29/78 [00:35<00:48,  1.00it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/78 [00:36<00:47,  1.02it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 31/78 [00:37<00:44,  1.05it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 32/78 [00:38<00:44,  1.04it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/78 [00:39<00:43,  1.04it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 34/78 [00:40<00:43,  1.02it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/78 [00:41<00:41,  1.03it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/78 [00:41<00:40,  1.03it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 37/78 [00:42<00:39,  1.03it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 38/78 [00:43<00:38,  1.04it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 39/78 [00:44<00:37,  1.03it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40/78 [00:45<00:36,  1.03it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 41/78 [00:46<00:35,  1.04it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 42/78 [00:47<00:34,  1.04it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 43/78 [00:48<00:32,  1.06it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 44/78 [00:49<00:31,  1.07it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 45/78 [00:50<00:31,  1.05it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 46/78 [00:51<00:31,  1.03it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 47/78 [00:52<00:29,  1.05it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48/78 [00:53<00:29,  1.02it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 49/78 [00:54<00:28,  1.00it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 50/78 [00:55<00:27,  1.01it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 51/78 [00:56<00:27,  1.01s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 52/78 [00:57<00:26,  1.01s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 53/78 [00:58<00:25,  1.03s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 54/78 [00:59<00:24,  1.02s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 55/78 [01:00<00:22,  1.00it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56/78 [01:01<00:22,  1.00s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 57/78 [01:02<00:20,  1.01it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 58/78 [01:03<00:20,  1.01s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 59/78 [01:04<00:19,  1.01s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 60/78 [01:05<00:17,  1.01it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 61/78 [01:06<00:16,  1.02it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 62/78 [01:07<00:15,  1.02it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 63/78 [01:08<00:14,  1.01it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 64/78 [01:09<00:13,  1.02it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 65/78 [01:10<00:12,  1.01it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 66/78 [01:11<00:12,  1.00s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 67/78 [01:12<00:10,  1.02it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 68/78 [01:13<00:09,  1.02it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 69/78 [01:14<00:08,  1.03it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 70/78 [01:15<00:07,  1.01it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 71/78 [01:16<00:06,  1.03it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 72/78 [01:17<00:05,  1.04it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 73/78 [01:18<00:04,  1.04it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 74/78 [01:19<00:04,  1.01s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 75/78 [01:20<00:03,  1.00s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 76/78 [01:21<00:02,  1.02s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 77/78 [01:22<00:01,  1.01s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [01:23<00:00,  1.14it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [01:23<00:00,  1.06s/it]\n",
      "\u001b[0m\n",
      "\u001b[34m2021-05-29 03:27:46,749 sagemaker_tensorflow_container.training WARNING  No model artifact is saved under path /opt/ml/model. Your training job will not save any model files to S3.\u001b[0m\n",
      "\u001b[34mFor details of how to construct your training script see:\u001b[0m\n",
      "\u001b[34mhttps://sagemaker.readthedocs.io/en/stable/using_tf.html#adapting-your-local-tensorflow-script\u001b[0m\n",
      "\u001b[34m2021-05-29 03:27:46,750 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 276\n",
      "Billable seconds: 276\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'model': f's3://{bucket}/models/yolov5/train-full/',\n",
    "               \n",
    "               'annot': f's3://{bucket}/atrw/detection/annotations/yolov5/ImageSets/Main',\n",
    "               'label': f's3://{bucket}/atrw/detection/annotations/yolov5/labels',\n",
    "               'train': f's3://{bucket}/atrw/detection/train/',\n",
    "               \n",
    "               'annot_test': f's3://{bucket}/atrw/detection/annotations/yolov5-test/ImageSets',\n",
    "               'label_test': f's3://{bucket}/atrw/detection/annotations/yolov5-test/labels',\n",
    "               'test': f's3://{bucket}/atrw/detection/test/'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e058d912",
   "metadata": {},
   "source": [
    "## Yolov5m Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56ba82d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TENSORFLOW CONTAINER (PY37)\n",
    "\n",
    "image_set = 'train'\n",
    "\n",
    "estimator = TensorFlow(entry_point='test.py',\n",
    "                        source_dir='./',\n",
    "                        role=role,\n",
    "                        instance_count=1,\n",
    "                        instance_type=\"ml.g4dn.xlarge\",\n",
    "                        framework_version=\"2.2\",\n",
    "                        py_version=\"py37\",\n",
    "                        hyperparameters={\n",
    "                            'img-size': 1920,\n",
    "                            'task': image_set,\n",
    "                            'weights': 'SM_CHANNEL_MODEL/best.pt',\n",
    "                            'data': 'atrw.yaml',\n",
    "                            'anno-json': 'data/atrw_detect_corner.json',\n",
    "                            'output-s3': f's3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-m/{image_set}',\n",
    "                            'save-s3': True\n",
    "                        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81c2b068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-29 03:47:19 Starting - Starting the training job...\n",
      "2021-05-29 03:47:43 Starting - Launching requested ML instancesProfilerReport-1622260034: InProgress\n",
      "......\n",
      "2021-05-29 03:48:43 Starting - Preparing the instances for training......\n",
      "2021-05-29 03:49:43 Downloading - Downloading input data.........\n",
      "2021-05-29 03:51:19 Training - Downloading the training image...\n",
      "2021-05-29 03:51:44 Training - Training image download completed. Training in progress.\u001b[34m2021-05-29 03:51:36.349475: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:425] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-05-29 03:51:36.353164: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:106] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2021-05-29 03:51:36.479458: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:425] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-05-29 03:51:38,951 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2021-05-29 03:51:43,437 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.7 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting matplotlib>=3.2.2\n",
      "  Downloading matplotlib-3.4.2-cp37-cp37m-manylinux1_x86_64.whl (10.3 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (1.18.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (4.2.0.32)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Pillow in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (7.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 8)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 9)) (1.4.1)\u001b[0m\n",
      "\u001b[34mCollecting torch>=1.7.0\n",
      "  Downloading torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1 MB)\u001b[0m\n",
      "\u001b[34mCollecting torchvision>=0.8.1\n",
      "  Downloading torchvision-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (17.4 MB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm>=4.41.0\n",
      "  Downloading tqdm-4.61.0-py2.py3-none-any.whl (75 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard>=2.4.1\n",
      "  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\u001b[0m\n",
      "\u001b[34mCollecting seaborn>=0.11.0\n",
      "  Downloading seaborn-0.11.1-py3-none-any.whl (285 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 20)) (1.0.3)\u001b[0m\n",
      "\u001b[34mCollecting thop\n",
      "  Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting Cython\n",
      "  Downloading Cython-0.29.23-cp37-cp37m-manylinux1_x86_64.whl (2.0 MB)\u001b[0m\n",
      "\u001b[34mCollecting pycocotools>=2.0\n",
      "  Downloading pycocotools-2.0.2.tar.gz (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.1)\u001b[0m\n",
      "\u001b[34mCollecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.4.7)\u001b[0m\n",
      "\u001b[34mCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/site-packages (from pycocotools>=2.0->-r requirements.txt (line 30)) (54.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas->-r requirements.txt (line 20)) (2021.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (2.23.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.36.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.36.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.15.4)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.27.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/site-packages (from torch>=1.7.0->-r requirements.txt (line 10)) (3.7.4.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.15.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.2.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.4.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.25.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (2020.12.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.4.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for pycocotools (setup.py): finished with status 'done'\n",
      "  Created wheel for pycocotools: filename=pycocotools-2.0.2-cp37-cp37m-linux_x86_64.whl size=273718 sha256=f748207a5e05fa0a3f6c0a366cd09991a9a4e47d374bdd87adad943e539eea66\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/cf/1b/e95c99c5f9d1648be3f500ca55e7ce55f24818b0f48336adaf\u001b[0m\n",
      "\u001b[34mSuccessfully built pycocotools\u001b[0m\n",
      "\u001b[34mInstalling collected packages: kiwisolver, cycler, torch, tensorboard-data-server, matplotlib, Cython, tqdm, torchvision, thop, tensorboard, seaborn, pycocotools\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.2.2\n",
      "    Uninstalling tensorboard-2.2.2:\n",
      "      Successfully uninstalled tensorboard-2.2.2\u001b[0m\n",
      "\u001b[34mSuccessfully installed Cython-0.29.23 cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.4.2 pycocotools-2.0.2 seaborn-0.11.1 tensorboard-2.5.0 tensorboard-data-server-0.6.1 thop-0.0.31.post2005241907 torch-1.8.1 torchvision-0.9.1 tqdm-4.61.0\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34mtensorflow-gpu 2.2.2 requires tensorboard<2.3.0,>=2.2.0, but you have tensorboard 2.5.0 which is incompatible.\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 21.0.1; however, version 21.1.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\n",
      "\u001b[0m\n",
      "\u001b[34m2021-05-29 03:52:34,659 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"label_test\": \"/opt/ml/input/data/label_test\",\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"annot_test\": \"/opt/ml/input/data/annot_test\",\n",
      "        \"model\": \"/opt/ml/input/data/model\",\n",
      "        \"label\": \"/opt/ml/input/data/label\",\n",
      "        \"annot\": \"/opt/ml/input/data/annot\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"output-s3\": \"s3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-m/train\",\n",
      "        \"data\": \"atrw.yaml\",\n",
      "        \"weights\": \"SM_CHANNEL_MODEL/best.pt\",\n",
      "        \"save-s3\": true,\n",
      "        \"task\": \"train\",\n",
      "        \"anno-json\": \"data/atrw_detect_corner.json\",\n",
      "        \"model_dir\": \"s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-29-03-46-39-074/model\",\n",
      "        \"img-size\": 1920\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"label_test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"annot_test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"model\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"label\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"annot\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tensorflow-training-2021-05-29-03-47-14-871\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-29-03-47-14-871/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"test\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"test.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"anno-json\":\"data/atrw_detect_corner.json\",\"data\":\"atrw.yaml\",\"img-size\":1920,\"model_dir\":\"s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-29-03-46-39-074/model\",\"output-s3\":\"s3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-m/train\",\"save-s3\":true,\"task\":\"train\",\"weights\":\"SM_CHANNEL_MODEL/best.pt\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=test.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"annot\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"annot_test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"label\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"label_test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"model\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"annot\",\"annot_test\",\"label\",\"label_test\",\"model\",\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=test\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-29-03-47-14-871/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"annot\":\"/opt/ml/input/data/annot\",\"annot_test\":\"/opt/ml/input/data/annot_test\",\"label\":\"/opt/ml/input/data/label\",\"label_test\":\"/opt/ml/input/data/label_test\",\"model\":\"/opt/ml/input/data/model\",\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"anno-json\":\"data/atrw_detect_corner.json\",\"data\":\"atrw.yaml\",\"img-size\":1920,\"model_dir\":\"s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-29-03-46-39-074/model\",\"output-s3\":\"s3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-m/train\",\"save-s3\":true,\"task\":\"train\",\"weights\":\"SM_CHANNEL_MODEL/best.pt\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"annot\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"annot_test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"label\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"label_test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"model\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2021-05-29-03-47-14-871\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-29-03-47-14-871/source/sourcedir.tar.gz\",\"module_name\":\"test\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"test.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--anno-json\",\"data/atrw_detect_corner.json\",\"--data\",\"atrw.yaml\",\"--img-size\",\"1920\",\"--model_dir\",\"s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-29-03-46-39-074/model\",\"--output-s3\",\"s3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-m/train\",\"--save-s3\",\"True\",\"--task\",\"train\",\"--weights\",\"SM_CHANNEL_MODEL/best.pt\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_LABEL_TEST=/opt/ml/input/data/label_test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_ANNOT_TEST=/opt/ml/input/data/annot_test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_MODEL=/opt/ml/input/data/model\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_LABEL=/opt/ml/input/data/label\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_ANNOT=/opt/ml/input/data/annot\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT-S3=s3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-m/train\u001b[0m\n",
      "\u001b[34mSM_HP_DATA=atrw.yaml\u001b[0m\n",
      "\u001b[34mSM_HP_WEIGHTS=SM_CHANNEL_MODEL/best.pt\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE-S3=true\u001b[0m\n",
      "\u001b[34mSM_HP_TASK=train\u001b[0m\n",
      "\u001b[34mSM_HP_ANNO-JSON=data/atrw_detect_corner.json\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-29-03-46-39-074/model\u001b[0m\n",
      "\u001b[34mSM_HP_IMG-SIZE=1920\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.7 test.py --anno-json data/atrw_detect_corner.json --data atrw.yaml --img-size 1920 --model_dir s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-29-03-46-39-074/model --output-s3 s3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-m/train --save-s3 True --task train --weights SM_CHANNEL_MODEL/best.pt\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mNamespace(anno_json='data/atrw_detect_corner.json', augment=False, batch_size=32, conf_thres=0.001, data='./data/atrw.yaml', device='', exist_ok=False, img_size=1920, iou_thres=0.6, model_dir='s3://sagemaker-us-east-1-652516965730/tensorflow-training-2021-05-29-03-46-39-074/model', name='exp', output_s3='s3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-m/train', project='runs/test', save_conf=True, save_hybrid=False, save_json=True, save_s3=True, save_txt=True, single_cls=False, task='train', verbose=False, weights=['/opt/ml/input/data/model/best.pt'])\u001b[0m\n",
      "\u001b[34mWARNING: Dataset not found, nonexistent paths: ['/opt/ml/code/val.txt']\u001b[0m\n",
      "\u001b[34mRunning bash data/scripts/setup_tiger.sh ...\u001b[0m\n",
      "\u001b[34m------------------------------SETUP ATRW-----------------------------------\u001b[0m\n",
      "\u001b[34mDataset autodownload success\n",
      "\u001b[0m\n",
      "\u001b[34m                 all        2485        5341       0.854       0.717       0.784        0.42\u001b[0m\n",
      "\u001b[34mSpeed: 46.8/1.0/47.8 ms inference/NMS/total per 1920x1920 image at batch-size 32\u001b[0m\n",
      "\u001b[34mEvaluating pycocotools mAP... saving runs/test/exp/best_predictions.json...\u001b[0m\n",
      "\u001b[34mloading annotations into memory...\u001b[0m\n",
      "\u001b[34mDone (t=0.08s)\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mLoading and preparing results...\u001b[0m\n",
      "\u001b[34mpycocotools unable to run: Results do not correspond to current coco set\u001b[0m\n",
      "\u001b[34mResults saved to runs/test/exp\u001b[0m\n",
      "\u001b[34m2485 labels saved to runs/test/exp/labels\u001b[0m\n",
      "\u001b[34mExecuting: aws s3 cp --recursive runs/test/exp s3://calvinandpogs-ee148/atrw/out/detection/yolov5/test-m/train/05-29-2021-03-55-05/runs/\u001b[0m\n",
      "\n",
      "2021-05-29 03:55:25 Uploading - Uploading generated training model\n",
      "2021-05-29 03:55:25 Completed - Training job completed\n",
      "\u001b[34mYOLOv5 ðŸš€ 2021-5-23 torch 1.8.1+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n",
      "\u001b[0m\n",
      "\u001b[34mFusing layers... \u001b[0m\n",
      "\u001b[34mModel Summary: 308 layers, 21037638 parameters, 0 gradients, 50.3 GFLOPS\u001b[0m\n",
      "\u001b[34m#015Scanning images:   0%|          | 0/2485 [00:00<?, ?it/s]#015#033[34m#033[1mtrain: #033[0mScanning 'train' images and labels... 180 found, 0 missing, 0 empty, 0 corrupted:   7%|â–‹         | 180/2485 [00:00<00:01, 1796.39it/s]#015#033[34m#033[1mtrain: #033[0mScanning 'train' images and labels... 379 found, 0 missing, 0 empty, 0 corrupted:  15%|â–ˆâ–Œ        | 379/2485 [00:00<00:01, 1905.56it/s]#015#033[34m#033[1mtrain: #033[0mScanning 'train' images and labels... 581 found, 0 missing, 0 empty, 0 corrupted:  23%|â–ˆâ–ˆâ–Ž       | 581/2485 [00:00<00:00, 1956.82it/s]#015#033[34m#033[1mtrain: #033[0mScanning 'train' images and labels... 786 found, 0 missing, 0 empty, 0 corrupted:  32%|â–ˆâ–ˆâ–ˆâ–      | 786/2485 [00:00<00:00, 1989.67it/s]#015#033[34m#033[1mtrain: #033[0mScanning 'train' images and labels... 988 found, 0 missing, 0 empty, 0 corrupted:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 988/2485 [00:00<00:00, 1997.86it/s]#015#033[34m#033[1mtrain: #033[0mScanning 'train' images and labels... 1189 found, 0 missing, 0 empty, 0 corrupted:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1189/2485 [00:00<00:00, 1999.66it/s]#015#033[34m#033[1mtrain: #033[0mScanning 'train' images and labels... 1390 found, 0 missing, 0 empty, 0 corrupted:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1390/2485 [00:00<00:00, 2000.74it/s]#015#033[34m#033[1mtrain: #033[0mScanning 'train' images and labels... 1592 found, 0 missing, 0 empty, 0 corrupted:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1592/2485 [00:00<00:00, 2005.43it/s]#015#033[34m#033[1mtrain: #033[0mScanning 'train' images and labels... 1795 found, 0 missing, 0 empty, 0 corrupted:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1795/2485 [00:00<00:00, 2010.46it/s]#015#033[34m#033[1mtrain: #033[0mScanning 'train' images and labels... 2000 found, 0 missing, 0 empty, 0 corrupted:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2000/2485 [00:01<00:00, 2019.69it/s]#015#033[34m#033[1mtrain: #033[0mScanning 'train' images and labels... 2212 found, 0 missing, 0 empty, 0 corrupted:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2212/2485 [00:01<00:00, 2049.13it/s]#015#033[34m#033[1mtrain: #033[0mScanning 'train' images and labels... 2485 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2485/2485 [00:01<00:00, 2122.59it/s]\u001b[0m\n",
      "\u001b[34m#033[34m#033[1mtrain: #033[0mNew cache created: train.cache\u001b[0m\n",
      "\u001b[34m#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   0%|          | 0/78 [00:00<?, ?it/s]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   1%|â–         | 1/78 [00:04<06:24,  5.00s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   3%|â–Ž         | 2/78 [00:08<05:03,  3.99s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   4%|â–         | 3/78 [00:10<04:13,  3.39s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   5%|â–Œ         | 4/78 [00:12<03:31,  2.86s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   6%|â–‹         | 5/78 [00:14<03:01,  2.49s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   8%|â–Š         | 6/78 [00:16<02:38,  2.20s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   9%|â–‰         | 7/78 [00:18<02:24,  2.04s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  10%|â–ˆ         | 8/78 [00:19<02:13,  1.91s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  12%|â–ˆâ–        | 9/78 [00:21<02:08,  1.86s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  13%|â–ˆâ–Ž        | 10/78 [00:23<02:02,  1.80s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  14%|â–ˆâ–        | 11/78 [00:25<02:00,  1.80s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  15%|â–ˆâ–Œ        | 12/78 [00:26<01:56,  1.77s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  17%|â–ˆâ–‹        | 13/78 [00:28<01:53,  1.74s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  18%|â–ˆâ–Š        | 14/78 [00:30<01:50,  1.73s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  19%|â–ˆâ–‰        | 15/78 [00:31<01:47,  1.71s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  21%|â–ˆâ–ˆ        | 16/78 [00:33<01:45,  1.70s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  22%|â–ˆâ–ˆâ–       | 17/78 [00:35<01:43,  1.69s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  23%|â–ˆâ–ˆâ–Ž       | 18/78 [00:36<01:41,  1.69s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  24%|â–ˆâ–ˆâ–       | 19/78 [00:38<01:39,  1.69s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  26%|â–ˆâ–ˆâ–Œ       | 20/78 [00:40<01:38,  1.69s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  27%|â–ˆâ–ˆâ–‹       | 21/78 [00:41<01:36,  1.69s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  28%|â–ˆâ–ˆâ–Š       | 22/78 [00:43<01:34,  1.69s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  29%|â–ˆâ–ˆâ–‰       | 23/78 [00:45<01:33,  1.70s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  31%|â–ˆâ–ˆâ–ˆ       | 24/78 [00:47<01:32,  1.70s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  32%|â–ˆâ–ˆâ–ˆâ–      | 25/78 [00:48<01:30,  1.71s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 26/78 [00:50<01:29,  1.71s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  35%|â–ˆâ–ˆâ–ˆâ–      | 27/78 [00:52<01:27,  1.71s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 28/78 [00:53<01:25,  1.71s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 29/78 [00:55<01:24,  1.72s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/78 [00:57<01:22,  1.72s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 31/78 [00:59<01:21,  1.73s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 32/78 [01:00<01:19,  1.73s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/78 [01:02<01:17,  1.72s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 34/78 [01:04<01:15,  1.73s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/78 [01:05<01:13,  1.72s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/78 [01:07<01:12,  1.72s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 37/78 [01:09<01:10,  1.72s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 38/78 [01:11<01:08,  1.72s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 39/78 [01:12<01:07,  1.73s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40/78 [01:14<01:05,  1.73s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 41/78 [01:16<01:03,  1.73s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 42/78 [01:18<01:02,  1.73s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 43/78 [01:19<01:00,  1.72s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 44/78 [01:21<00:59,  1.74s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 45/78 [01:23<00:58,  1.78s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 46/78 [01:25<00:56,  1.77s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 47/78 [01:26<00:54,  1.76s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48/78 [01:28<00:52,  1.76s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 49/78 [01:30<00:50,  1.75s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 50/78 [01:32<00:49,  1.75s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 51/78 [01:33<00:47,  1.75s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 52/78 [01:35<00:45,  1.74s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 53/78 [01:37<00:43,  1.74s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 54/78 [01:39<00:41,  1.74s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 55/78 [01:40<00:40,  1.74s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56/78 [01:42<00:38,  1.74s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 57/78 [01:44<00:36,  1.74s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 58/78 [01:46<00:34,  1.75s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 59/78 [01:47<00:33,  1.76s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 60/78 [01:49<00:31,  1.75s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 61/78 [01:51<00:29,  1.75s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 62/78 [01:53<00:27,  1.75s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 63/78 [01:54<00:26,  1.75s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 64/78 [01:56<00:24,  1.76s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 65/78 [01:58<00:22,  1.76s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 66/78 [02:00<00:21,  1.76s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 67/78 [02:01<00:19,  1.76s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 68/78 [02:03<00:17,  1.76s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 69/78 [02:05<00:15,  1.77s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 70/78 [02:07<00:14,  1.77s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 71/78 [02:09<00:12,  1.77s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 72/78 [02:10<00:10,  1.78s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 73/78 [02:12<00:08,  1.78s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 74/78 [02:14<00:07,  1.79s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 75/78 [02:16<00:05,  1.79s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 76/78 [02:17<00:03,  1.79s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 77/78 [02:19<00:01,  1.80s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [02:20<00:00,  1.61s/it]#015               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [02:20<00:00,  1.81s/it]\n",
      "\u001b[0m\n",
      "\u001b[34m2021-05-29 03:55:18,343 sagemaker_tensorflow_container.training WARNING  No model artifact is saved under path /opt/ml/model. Your training job will not save any model files to S3.\u001b[0m\n",
      "\u001b[34mFor details of how to construct your training script see:\u001b[0m\n",
      "\u001b[34mhttps://sagemaker.readthedocs.io/en/stable/using_tf.html#adapting-your-local-tensorflow-script\u001b[0m\n",
      "\u001b[34m2021-05-29 03:55:18,344 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 353\n",
      "Billable seconds: 353\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'model': f's3://{bucket}/models/yolov5/train-full-m/',\n",
    "               \n",
    "               'annot': f's3://{bucket}/atrw/detection/annotations/yolov5/ImageSets/Main',\n",
    "               'label': f's3://{bucket}/atrw/detection/annotations/yolov5/labels',\n",
    "               'train': f's3://{bucket}/atrw/detection/train/',\n",
    "               \n",
    "               'annot_test': f's3://{bucket}/atrw/detection/annotations/yolov5-test/ImageSets',\n",
    "               'label_test': f's3://{bucket}/atrw/detection/annotations/yolov5-test/labels',\n",
    "               'test': f's3://{bucket}/atrw/detection/test/'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc03c20",
   "metadata": {},
   "source": [
    "## Testing Subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b884b463",
   "metadata": {},
   "source": [
    "### Fractional Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "285e7c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "\n",
    "sets = [16, 8, 4, 2]\n",
    "\n",
    "for set in sets:\n",
    "    estimator = TensorFlow(entry_point='test.py',\n",
    "                            source_dir='./',\n",
    "                            role=role,\n",
    "                            instance_count=1,\n",
    "                            instance_type=\"ml.g4dn.xlarge\",\n",
    "                            framework_version=\"2.2\",\n",
    "                            py_version=\"py37\",\n",
    "                            hyperparameters={\n",
    "                                'img-size': 1920,\n",
    "                                'task': 'test',\n",
    "                                'weights': 'SM_CHANNEL_MODEL/best.pt',\n",
    "                                'data': f'atrw{set}.yaml',\n",
    "                                'anno-json': 'data/atrw_detect_center.json',\n",
    "                                'output-s3': f's3://calvinandpogs-ee148/atrw/out/detection/yolov5/frac/test{set}/',\n",
    "                                'save-s3': True\n",
    "                            }\n",
    "    )\n",
    "    estimator.fit({'model': f's3://{bucket}/models/yolov5/train{set}/',\n",
    "                   'annot_test': f's3://{bucket}/atrw/detection/annotations/yolov5-test/ImageSets',\n",
    "                   'label_test': f's3://{bucket}/atrw/detection/annotations/yolov5-test/labels',\n",
    "                   'test': f's3://{bucket}/atrw/detection/test/'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3350d3c",
   "metadata": {},
   "source": [
    "### Clustering Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa17dd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "\n",
    "sets = [16, 8, 4, 2]\n",
    "\n",
    "for set in sets:\n",
    "    estimator = TensorFlow(entry_point='test.py',\n",
    "                            source_dir='./',\n",
    "                            role=role,\n",
    "                            instance_count=1,\n",
    "                            instance_type=\"ml.g4dn.xlarge\",\n",
    "                            framework_version=\"2.2\",\n",
    "                            py_version=\"py37\",\n",
    "                            hyperparameters={\n",
    "                                'img-size': 1920,\n",
    "                                'task': 'test',\n",
    "                                'weights': 'SM_CHANNEL_MODEL/best.pt',\n",
    "                                'data': 'atrw.yaml',\n",
    "                                'anno-json': 'data/atrw_detect_center.json',\n",
    "                                'output-s3': f's3://calvinandpogs-ee148/atrw/out/detection/yolov5/bg-split/test/split{set}/',\n",
    "                                'save-s3': True\n",
    "                            }\n",
    "    )\n",
    "    estimator.fit({'model': f's3://{bucket}/models/yolov5/bg-split/split{set}/',\n",
    "                   'annot_test': f's3://{bucket}/atrw/detection/annotations/yolov5-test/ImageSets',\n",
    "                   'label_test': f's3://{bucket}/atrw/detection/annotations/yolov5-test/labels',\n",
    "                   'test': f's3://{bucket}/atrw/detection/test/'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9294bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_latest_p37",
   "language": "python",
   "name": "conda_mxnet_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
